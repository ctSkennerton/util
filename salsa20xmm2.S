
	.text
	.p2align	5
	.globl	_ECRYPT_keystream_bytes
	.globl	ECRYPT_keystream_bytes
_ECRYPT_keystream_bytes:
ECRYPT_keystream_bytes:
	mov	%esp,%eax
	and	$31,%eax
	add	$96,%eax
	sub	%eax,%esp
	movl	%eax,0(%esp)
	movl	%ebx,4(%esp)
	movl	%esi,8(%esp)
	movl	%edi,12(%esp)
	movl	%ebp,16(%esp)
	movl	4(%esp,%eax),%edx
	movl	8(%esp,%eax),%esi
	mov	 %esi,%edi
	movl	12(%esp,%eax),%ebx
	cmp	 $0,%ebx
	jbe	._done
	mov	 $0,%eax
	mov	 %ebx,%ecx
	rep	stosb
	subl	%ebx,%edi
	jmp	._start

	.text
	.p2align	5
	.globl	_ECRYPT_decrypt_bytes
	.globl	ECRYPT_decrypt_bytes
_ECRYPT_decrypt_bytes:
ECRYPT_decrypt_bytes:
	mov	%esp,%eax
	and	$31,%eax
	add	$96,%eax
	sub	%eax,%esp
	movl	%eax,0(%esp)
	movl	%ebx,4(%esp)
	movl	%esi,8(%esp)
	movl	%edi,12(%esp)
	movl	%ebp,16(%esp)
	movl	4(%esp,%eax),%edx
	movl	8(%esp,%eax),%esi
	movl	12(%esp,%eax),%edi
	movl	16(%esp,%eax),%ebx
	cmp	 $0,%ebx
	jbe	._done
	jmp	._start

	.text
	.p2align	5
	.globl	_ECRYPT_encrypt_bytes
	.globl	ECRYPT_encrypt_bytes
_ECRYPT_encrypt_bytes:
ECRYPT_encrypt_bytes:
	mov	%esp,%eax
	and	$31,%eax
	add	$96,%eax
	sub	%eax,%esp
	movl	%eax,0(%esp)
	movl	%ebx,4(%esp)
	movl	%esi,8(%esp)
	movl	%edi,12(%esp)
	movl	%ebp,16(%esp)
	movl	4(%esp,%eax),%edx
	movl	8(%esp,%eax),%esi
	movl	12(%esp,%eax),%edi
	movl	16(%esp,%eax),%ebx
	cmp	 $0,%ebx
	jbe	._done
._start:
._bytesatleast1:
	cmp	 $64,%ebx
	jae	._nocopy
	movl	%edi,20(%esp)
	leal	32(%esp),%edi
	mov	 %ebx,%ecx
	rep	movsb
	leal	32(%esp),%edi
	leal	32(%esp),%esi
._nocopy:
	movl	%ebx,24(%esp)
	movdqa	0(%edx),%xmm0
	movdqa	16(%edx),%xmm1
	movdqa	32(%edx),%xmm2
	movdqa	48(%edx),%xmm3
	movdqa	%xmm1,%xmm4
	mov	 $20,%eax
._mainloop:
	paddd	%xmm0,%xmm4
	movdqa	%xmm0,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$7,%xmm4
	psrld	$25,%xmm6
	pxor	 %xmm4,%xmm3
	pxor	 %xmm6,%xmm3
	paddd	%xmm3,%xmm5
	movdqa	%xmm3,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$9,%xmm5
	psrld	$23,%xmm6
	pxor	 %xmm5,%xmm2
	pshufd	$0x93,%xmm3,%xmm3
	pxor	 %xmm6,%xmm2
	paddd	%xmm2,%xmm4
	movdqa	%xmm2,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$13,%xmm4
	psrld	$19,%xmm6
	pxor	 %xmm4,%xmm1
	pshufd	$0x4e,%xmm2,%xmm2
	pxor	 %xmm6,%xmm1
	paddd	%xmm1,%xmm5
	movdqa	%xmm3,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$18,%xmm5
	psrld	$14,%xmm6
	pxor	 %xmm5,%xmm0
	pshufd	$0x39,%xmm1,%xmm1
	pxor	 %xmm6,%xmm0
	paddd	%xmm0,%xmm4
	movdqa	%xmm0,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$7,%xmm4
	psrld	$25,%xmm6
	pxor	 %xmm4,%xmm1
	pxor	 %xmm6,%xmm1
	paddd	%xmm1,%xmm5
	movdqa	%xmm1,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$9,%xmm5
	psrld	$23,%xmm6
	pxor	 %xmm5,%xmm2
	pshufd	$0x93,%xmm1,%xmm1
	pxor	 %xmm6,%xmm2
	paddd	%xmm2,%xmm4
	movdqa	%xmm2,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$13,%xmm4
	psrld	$19,%xmm6
	pxor	 %xmm4,%xmm3
	pshufd	$0x4e,%xmm2,%xmm2
	pxor	 %xmm6,%xmm3
	paddd	%xmm3,%xmm5
	movdqa	%xmm1,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$18,%xmm5
	psrld	$14,%xmm6
	pxor	 %xmm5,%xmm0
	pshufd	$0x39,%xmm3,%xmm3
	pxor	 %xmm6,%xmm0
	paddd	%xmm0,%xmm4
	movdqa	%xmm0,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$7,%xmm4
	psrld	$25,%xmm6
	pxor	 %xmm4,%xmm3
	pxor	 %xmm6,%xmm3
	paddd	%xmm3,%xmm5
	movdqa	%xmm3,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$9,%xmm5
	psrld	$23,%xmm6
	pxor	 %xmm5,%xmm2
	pshufd	$0x93,%xmm3,%xmm3
	pxor	 %xmm6,%xmm2
	paddd	%xmm2,%xmm4
	movdqa	%xmm2,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$13,%xmm4
	psrld	$19,%xmm6
	pxor	 %xmm4,%xmm1
	pshufd	$0x4e,%xmm2,%xmm2
	pxor	 %xmm6,%xmm1
	paddd	%xmm1,%xmm5
	movdqa	%xmm3,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$18,%xmm5
	psrld	$14,%xmm6
	pxor	 %xmm5,%xmm0
	pshufd	$0x39,%xmm1,%xmm1
	pxor	 %xmm6,%xmm0
	paddd	%xmm0,%xmm4
	movdqa	%xmm0,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$7,%xmm4
	psrld	$25,%xmm6
	pxor	 %xmm4,%xmm1
	pxor	 %xmm6,%xmm1
	paddd	%xmm1,%xmm5
	movdqa	%xmm1,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$9,%xmm5
	psrld	$23,%xmm6
	pxor	 %xmm5,%xmm2
	pshufd	$0x93,%xmm1,%xmm1
	pxor	 %xmm6,%xmm2
	paddd	%xmm2,%xmm4
	movdqa	%xmm2,%xmm5
	movdqa	%xmm4,%xmm6
	pslld	$13,%xmm4
	psrld	$19,%xmm6
	pxor	 %xmm4,%xmm3
	pshufd	$0x4e,%xmm2,%xmm2
	pxor	 %xmm6,%xmm3
	sub	 $4,%eax
	paddd	%xmm3,%xmm5
	movdqa	%xmm1,%xmm4
	movdqa	%xmm5,%xmm6
	pslld	$18,%xmm5
	psrld	$14,%xmm6
	pxor	 %xmm5,%xmm0
	pshufd	$0x39,%xmm3,%xmm3
	pxor	 %xmm6,%xmm0
	ja	._mainloop
	paddd	0(%edx),%xmm0
	paddd	16(%edx),%xmm1
	paddd	32(%edx),%xmm2
	paddd	48(%edx),%xmm3
	movd	  %xmm0,%eax
	movd	  %xmm1,%ecx
	movd	  %xmm2,%ebx
	movd	  %xmm3,%ebp
	pshufd	$0x39,%xmm0,%xmm0
	pshufd	$0x39,%xmm1,%xmm1
	pshufd	$0x39,%xmm2,%xmm2
	pshufd	$0x39,%xmm3,%xmm3
	xorl	0(%esi),%eax
	xorl	48(%esi),%ecx
	xorl	32(%esi),%ebx
	xorl	16(%esi),%ebp
	movl	%eax,0(%edi)
	movl	%ecx,48(%edi)
	movl	%ebx,32(%edi)
	movl	%ebp,16(%edi)
	movd	  %xmm0,%eax
	movd	  %xmm1,%ecx
	movd	  %xmm2,%ebx
	movd	  %xmm3,%ebp
	pshufd	$0x39,%xmm0,%xmm0
	pshufd	$0x39,%xmm1,%xmm1
	pshufd	$0x39,%xmm2,%xmm2
	pshufd	$0x39,%xmm3,%xmm3
	xorl	20(%esi),%eax
	xorl	4(%esi),%ecx
	xorl	52(%esi),%ebx
	xorl	36(%esi),%ebp
	movl	%eax,20(%edi)
	movl	%ecx,4(%edi)
	movl	%ebx,52(%edi)
	movl	%ebp,36(%edi)
	movd	  %xmm0,%eax
	movd	  %xmm1,%ecx
	movd	  %xmm2,%ebx
	movd	  %xmm3,%ebp
	pshufd	$0x39,%xmm0,%xmm0
	pshufd	$0x39,%xmm1,%xmm1
	pshufd	$0x39,%xmm2,%xmm2
	pshufd	$0x39,%xmm3,%xmm3
	xorl	40(%esi),%eax
	xorl	24(%esi),%ecx
	xorl	8(%esi),%ebx
	xorl	56(%esi),%ebp
	movl	%eax,40(%edi)
	movl	%ecx,24(%edi)
	movl	%ebx,8(%edi)
	movl	%ebp,56(%edi)
	movd	  %xmm0,%eax
	movd	  %xmm1,%ecx
	movd	  %xmm2,%ebx
	movd	  %xmm3,%ebp
	xorl	60(%esi),%eax
	xorl	44(%esi),%ecx
	xorl	28(%esi),%ebx
	xorl	12(%esi),%ebp
	movl	%eax,60(%edi)
	movl	%ecx,44(%edi)
	movl	%ebx,28(%edi)
	movl	%ebp,12(%edi)
	movl	24(%esp),%ebx
	movl	32(%edx),%eax
	movl	52(%edx),%ecx
	add	 $1,%eax
	adc	$0,%ecx
	movl	%eax,32(%edx)
	movl	%ecx,52(%edx)
	cmp	 $64,%ebx
	ja	._bytesatleast65
	jae	._bytesatleast64
	mov	 %edi,%esi
	movl	20(%esp),%edi
	mov	 %ebx,%ecx
	rep	movsb
._bytesatleast64:
._done:
	movl	0(%esp),%eax
	movl	4(%esp),%ebx
	movl	8(%esp),%esi
	movl	12(%esp),%edi
	movl	16(%esp),%ebp
	add	%eax,%esp
	ret
._bytesatleast65:
	sub	 $64,%ebx
	add	 $64,%edi
	add	 $64,%esi
	jmp	._bytesatleast1

	.text
	.p2align	5
	.globl	_ECRYPT_init
	.globl	ECRYPT_init
_ECRYPT_init:
ECRYPT_init:
	mov	%esp,%eax
	and	$31,%eax
	add	$96,%eax
	sub	%eax,%esp
	add	%eax,%esp
	ret

	.text
	.p2align	5
	.globl	_ECRYPT_keysetup
	.globl	ECRYPT_keysetup
_ECRYPT_keysetup:
ECRYPT_keysetup:
	mov	%esp,%eax
	and	$31,%eax
	add	$96,%eax
	sub	%eax,%esp
	movl	%eax,0(%esp)
	movl	%ebx,4(%esp)
	movl	%esi,8(%esp)
	movl	%edi,12(%esp)
	movl	%ebp,16(%esp)
	movl	8(%esp,%eax),%ecx
	movl	12(%esp,%eax),%edx
	movl	4(%esp,%eax),%eax
	movl	0(%ecx),%ebx
	movl	4(%ecx),%esi
	movl	8(%ecx),%edi
	movl	12(%ecx),%ebp
	movl	%ebx,20(%eax)
	movl	%esi,40(%eax)
	movl	%edi,60(%eax)
	movl	%ebp,48(%eax)
	cmp	 $256,%edx
	jb	._kbits128
._kbits256:
	movl	16(%ecx),%edx
	movl	20(%ecx),%ebx
	movl	24(%ecx),%esi
	movl	28(%ecx),%ecx
	movl	%edx,28(%eax)
	movl	%ebx,16(%eax)
	movl	%esi,36(%eax)
	movl	%ecx,56(%eax)
	mov	 $1634760805,%ecx
	mov	 $857760878,%edx
	mov	 $2036477234,%ebx
	mov	 $1797285236,%esi
	movl	%ecx,0(%eax)
	movl	%edx,4(%eax)
	movl	%ebx,8(%eax)
	movl	%esi,12(%eax)
	jmp	._keysetupdone
._kbits128:
	movl	0(%ecx),%edx
	movl	4(%ecx),%ebx
	movl	8(%ecx),%esi
	movl	12(%ecx),%ecx
	movl	%edx,28(%eax)
	movl	%ebx,16(%eax)
	movl	%esi,36(%eax)
	movl	%ecx,56(%eax)
	mov	 $1634760805,%ecx
	mov	 $824206446,%edx
	mov	 $2036477238,%ebx
	mov	 $1797285236,%esi
	movl	%ecx,0(%eax)
	movl	%edx,4(%eax)
	movl	%ebx,8(%eax)
	movl	%esi,12(%eax)
._keysetupdone:
	movl	0(%esp),%eax
	movl	4(%esp),%ebx
	movl	8(%esp),%esi
	movl	12(%esp),%edi
	movl	16(%esp),%ebp
	add	%eax,%esp
	ret

	.text
	.p2align	5
	.globl	_ECRYPT_ivsetup
	.globl	ECRYPT_ivsetup
_ECRYPT_ivsetup:
ECRYPT_ivsetup:
	mov	%esp,%eax
	and	$31,%eax
	add	$96,%eax
	sub	%eax,%esp
	movl	%eax,0(%esp)
	movl	%ebx,4(%esp)
	movl	%esi,8(%esp)
	movl	%edi,12(%esp)
	movl	%ebp,16(%esp)
	movl	8(%esp,%eax),%ecx
	movl	4(%esp,%eax),%eax
	movl	0(%ecx),%edx
	movl	4(%ecx),%ecx
	mov	 $0,%ebx
	mov	 $0,%esi
	movl	%edx,24(%eax)
	movl	%ecx,44(%eax)
	movl	%ebx,32(%eax)
	movl	%esi,52(%eax)
	movl	0(%esp),%eax
	movl	4(%esp),%ebx
	movl	8(%esp),%esi
	movl	12(%esp),%edi
	movl	16(%esp),%ebp
	add	%eax,%esp
	ret
